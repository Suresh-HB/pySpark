{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Author: Suresh <br>\n",
    "@Date: 2024-09-04 <br>\n",
    "@Last Modified by: Suresh <br>\n",
    "@Last Modified: 2024-09-04 <br>\n",
    "@Title :   Average number of deaths by day (Continents and Countries) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                           Countries with Average number of deaths by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|Country/Region|  Avg_Daily_Deaths|\n",
      "+--------------+------------------+\n",
      "|            US|58571.335106382976|\n",
      "|United Kingdom|21264.760638297874|\n",
      "|        Brazil|20946.989361702126|\n",
      "|         Italy| 19721.89893617021|\n",
      "|        France|16215.553191489362|\n",
      "|         Spain| 16133.13829787234|\n",
      "|        Mexico| 9192.962765957447|\n",
      "|         India| 5913.994680851064|\n",
      "|          Iran| 5447.531914893617|\n",
      "|       Belgium| 5125.952127659574|\n",
      "|       Germany| 4634.691489361702|\n",
      "|        Canada| 3721.095744680851|\n",
      "|         China|3576.6648936170213|\n",
      "|          Peru| 3468.686170212766|\n",
      "|   Netherlands|  3310.18085106383|\n",
      "|        Russia| 3294.601063829787|\n",
      "|        Turkey| 2479.021276595745|\n",
      "|        Sweden|2387.8351063829787|\n",
      "|       Ecuador| 1843.712765957447|\n",
      "|         Chile|1715.3191489361702|\n",
      "+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Covid19Analysis\").getOrCreate()\n",
    "\n",
    "\n",
    "file_path = r\"file:///E:/microsoft-SQL/covid-kaggle-dataset/covid_19_clean_complete.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "df.createOrReplaceTempView(\"covid_data\")\n",
    "\n",
    "avg_daily_deaths_sql = \"\"\"\n",
    "    SELECT `Country/Region`, AVG(Daily_Deaths) AS Avg_Daily_Deaths \n",
    "    FROM \n",
    "        (SELECT `Country/Region`, `Date`, SUM(Deaths) AS Daily_Deaths \n",
    "         FROM covid_data \n",
    "         GROUP BY `Country/Region`, `Date`) AS daily_deaths\n",
    "    GROUP BY `Country/Region` \n",
    "    ORDER BY Avg_Daily_Deaths DESC\n",
    "\"\"\"\n",
    "\n",
    "avg_daily_deaths_df = spark.sql(avg_daily_deaths_sql)\n",
    "\n",
    "avg_daily_deaths_df.show()\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                            Continents  with Average number of deaths by day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           Continent|  Avg_Daily_Deaths|\n",
      "+--------------------+------------------+\n",
      "|            Americas| 102974.9574468085|\n",
      "|              Europe|102505.53191489361|\n",
      "|Eastern Mediterra...|10234.196808510638|\n",
      "|     South-East Asia| 7756.031914893617|\n",
      "|     Western Pacific| 4959.734042553191|\n",
      "|              Africa| 2340.308510638298|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Covid19Analysis\").getOrCreate()\n",
    "\n",
    "\n",
    "file_path = \"file:///E:/microsoft-SQL/covid-kaggle-dataset/covid_19_clean_complete.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "df.createOrReplaceTempView(\"covid_data\")\n",
    "\n",
    "\n",
    "avg_daily_deaths_sql = \"\"\"\n",
    "    SELECT `WHO Region` AS Continent, AVG(Daily_Deaths) AS Avg_Daily_Deaths \n",
    "    FROM \n",
    "        (SELECT `WHO Region`, `Date`, SUM(Deaths) AS Daily_Deaths \n",
    "         FROM covid_data \n",
    "         GROUP BY `WHO Region`, `Date`) AS daily_deaths\n",
    "    GROUP BY `WHO Region` \n",
    "    ORDER BY Avg_Daily_Deaths DESC\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "avg_daily_deaths_df = spark.sql(avg_daily_deaths_sql)\n",
    "\n",
    "avg_daily_deaths_df.show()\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
